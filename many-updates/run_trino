#!/usr/bin/env bash

set -e

NUM_REPS=50

SCHEMA_NAME=many_updates
BUCKET_NAME=many-updates

OUTPUT_BASE_DIR=results
mkdir -p "$OUTPUT_BASE_DIR"

TRINO_SESSION='--session=hive.hive_storage_format=PARQUET --session=delta.compression_codec=GZIP --session=iceberg.compression_codec=GZIP'

for CATALOG in iceberg delta; do

    OUTPUT_DIR="$OUTPUT_BASE_DIR/$CATALOG"
    if [[ -d "$OUTPUT_DIR" ]]; then
        echo "$OUTPUT_DIR already exists"
        exit 1
    fi

    $TRINO_HOME/bin/trino $TRINO_SESSION --catalog "$CATALOG" --execute 'DROP SCHEMA IF EXISTS $SCHEMA_NAME CASCADE;'
    mcli mb "minio/$BUCKET_NAME"
    mcli rb --force "minio/$BUCKET_NAME"

    mkdir -p "$OUTPUT_DIR"/{sar,trace_op,trace_select,runtime_op,runtime_select,minio_du,minio_ls,hms}

    mcli mb "minio/$BUCKET_NAME"
    $TRINO_HOME/bin/trino $TRINO_SESSION --catalog "$CATALOG" --execute "CREATE SCHEMA IF NOT EXISTS $CATALOG.$SCHEMA_NAME WITH (location = 's3a://$BUCKET_NAME/');"

    # Relies on hive.storage-format, iceberg.file-format, and *.compression-codec being set
    $TRINO_HOME/bin/trino $TRINO_SESSION --catalog "$CATALOG" --schema "$SCHEMA_NAME" --execute 'CREATE TABLE data (key INT, value INT);'
    $TRINO_HOME/bin/trino $TRINO_SESSION --catalog "$CATALOG" --schema "$SCHEMA_NAME" --execute 'INSERT INTO data (key, value) VALUES (1, 0);'

    # Start sar monitoring
    sar -o "$OUTPUT_DIR/sar/benchmark.sar" -u -r -b -d --dev=nvme0n1 1 &> /dev/null &
    SAR_PID=$!

    sleep 3

    for REP in $(seq -w 1 "$NUM_REPS"); do

        QUERY_ID="${CATALOG}_${REP}_op_$(openssl rand -hex 4)"
        mcli admin trace minio > "$OUTPUT_DIR/trace_op/$REP" &
        TRACE_PID=$!
        $TRINO_HOME/bin/trino $TRINO_SESSION --catalog "$CATALOG" --schema "$SCHEMA_NAME" --execute "UPDATE data SET value = $((10#$REP)) WHERE key = 1;" &> /dev/null
        kill -SIGINT $TRACE_PID
        $TRINO_HOME/bin/trino $TRINO_SESSION --execute "SELECT CAST(TO_UNIXTIME(started) AS INT), TO_MILLISECONDS(\"end\" - started) FROM system.runtime.queries WHERE source = '$QUERY_ID';" --output-format CSV_UNQUOTED 2>/dev/null > "$OUTPUT_DIR/runtime_op/$REP"

        QUERY_ID="${CATALOG}_${REP}_select_$(openssl rand -hex 4)"
        mcli admin trace minio > "$OUTPUT_DIR/trace_select/$REP" &
        TRACE_PID=$!
        $TRINO_HOME/bin/trino $TRINO_SESSION --source "$QUERY_ID" --catalog "$CATALOG" --schema "$SCHEMA_NAME" --execute 'SELECT * FROM data;' --output-format NULL
        kill -SIGINT $TRACE_PID
        $TRINO_HOME/bin/trino $TRINO_SESSION --execute "SELECT CAST(TO_UNIXTIME(started) AS INT), TO_MILLISECONDS(\"end\" - started) FROM system.runtime.queries WHERE source = '$QUERY_ID';" --output-format CSV_UNQUOTED 2>/dev/null > "$OUTPUT_DIR/runtime_select/$REP"

        # Collect MinIO bucket size and number of objects
        s3cmd du "s3://$BUCKET_NAME" > "$OUTPUT_DIR/minio_du/$REP"

        # Collect HMS SQL dump and size
        sudo -u postgres pg_dump hms > "$OUTPUT_DIR/hms/$REP"

        echo "$CATALOG: $REP / $NUM_REPS"

    done

    # Stop sar monitoring
    kill -SIGINT $SAR_PID

    $TRINO_HOME/bin/trino $TRINO_SESSION --catalog "$CATALOG" --execute 'DROP SCHEMA $SCHEMA_NAME CASCADE;'
    mcli rb --force "minio/$BUCKET_NAME"

done

# Make a copy of the connector config
mkdir -p "$OUTPUT_BASE_DIR/conf"
cp $TRINO_HOME/etc/catalog/*.properties "$OUTPUT_BASE_DIR/conf/"
